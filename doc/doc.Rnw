\documentclass[12pt, a4paper, oneside]{article}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{enumerate}

\newcommand\ci{\perp\!\!\!\perp}

% \usepackage{pdflscape}

% font size could be 10pt (default), 11pt or 12 pt
% paper size coulde be letterpaper (default), legalpaper, executivepaper,
% a4paper, a5paper or b5paper
% side coulde be oneside (default) or twoside 
% columns coulde be onecolumn (default) or twocolumn
% graphics coulde be final (default) or draft 
%
% titlepage coulde be notitlepage (default) or titlepage which 
% makes an extra page for title 
% 
% paper alignment coulde be portrait (default) or landscape 
%
% equations coulde be 
%   default number of the equation on the rigth and equation centered 
%   leqno number on the left and equation centered 
%   fleqn number on the rigth and  equation on the left side
%   
\title{MDM Assignment 2}
\author{Marco Vassena  \\
    4110161 \\
    \and 
    Philipp Hausmann \\
    4003373 \\
    }

\date{\today} 
\begin{document}

<<setup, echo=FALSE, cache=FALSE,include=FALSE>>=
source('../src/analysis.r', chdir=TRUE)
library(knitr)
library(xtable)
library(igraph)
# For answer (e) during lots of iterations, 
# loglin doesn't converge and prints warning messages (Warning: algorithm did not converge)
options(warn=-1)  
@

\maketitle

\tableofcontents


\section{Problem description}
The goal of this assignment is to implement a hill-climbing algorithm to
learn graphical models from data and to study its behaviour with different parameters.

\section{Analysis}


\begin{enumerate}[(a)]

\item
A graphical model is totally represented by its independence graph, because all
the constraints (u-terms set to 0) can be read from it.
Therefore counting the number of graphical models comes down to counting the 
number of possible independence graphs, which are undirected graphs with as many
nodes as variables in the model.
In a graph with $k$ nodes, there are $k \choose 2$ possible undirected edges:
\[ {k \choose 2} = \frac{k!}{2! (k - 2)!} = \frac{k(k -1)}{2} \]
The first node of an edge can be chosen among $k$ elements, the second node among
the remaining $k - 1$ (we do not allow self loops), finally we divide by 2 
because the edges are undirected, thus an edge and the edge obtained swapping the
vertices count as one.
The number of different graphs with $k$ nodes corresponds to the total number 
of subsets of the set of all possible edges. A set with $n$ elements has $2^n$ 
subsets, because each element can be included or not in any subset.
Therefore the number of graphical models for a model with $k$ variables is $2^{k \choose 2}$.
This data set contains $10$ nodes, therefore the number of different 
graphical models is:
\[2^{10 \choose 2} = 35184372088832 \]

% R code: 2^choose(10,2)

%B
\item
% http://www.cs.uu.nl/docs/vakken/mdm/Slides/dm-graphmod-1.pdf, slide 7
Each cell of the table of counts contains the number of rows in a the data set 
whose attributes have a certain combination of values.
Therefore the number of cells of a table of counts correspond to the total 
number of possible configurations of the attributes values, which is the
product of the number of possible values of each attribute.
We report in table \ref{tbl:ans-a-values}, the variables of the model, with the number
of possible values for each attribute.

\begin{table}
  \begin{center}
    \begin{tabular}{ | c | c | }
      \hline
      variable & \# values \\ \hline
      cat1 & 9 \\ \hline
      death & 2 \\ \hline
      swang1 & 2 \\  \hline
      gender & 2 \\ \hline
      race & 3 \\ \hline
      ninsclas & 6 \\ \hline
      income & 4 \\ \hline
      ca & 3 \\ \hline
      age & 5 \\ \hline
      meanbp1 & 2 \\ \hline
    \end{tabular}
    \caption{Number of levels for each variable of the model}
    \label{tbl:ans-a-values}
  \end{center}
\end{table}

Therefore the number of cells of the table of counts for this data set is given by
$9 \times 2^3 \times 3 \times 6 \times 4 \times 3 \times 5 \times 2$, which is equal to $155520$.

The saturated model does not assume any (conditional) independency among the variables,
thus all its probabilities are estimated counting how many times a certain combination of values
occurs, divided by the total number of observation:
\[ \hat{p}(x_1 \dots x_n) = \frac{n(x_1 \dots x_n)}{N}\]
Therefore we need to consider again all the possible configurations of values. However
since all the probabilities must sum to one, we can leave out one of those. 

The number of parameters of the saturated models is the number of cells of the table
of counts minus 1, which gives $155519$ parameters.

% length(table(d)): 155520

%C
\item
The nodes have been numbered according to table \ref{tbl:ans-c-nodes}. The cliques of the
resulting model can be seen in table \ref{tbl:ans-c-cliq}. Figure \ref{grp:ans-c-graph} shows
the independence graph of the model.

\begin{table}
  \begin{center}
    \begin{tabular}{ | c | c | }
      \hline
      N & variable \\ \hline
      1 & cat1 \\ \hline
      2 & death \\ \hline
      3 & swang1 \\  \hline
      4 & gender \\ \hline
      5 & race \\ \hline
      6 & ninsclas \\ \hline
      7 & income \\ \hline
      8 & ca \\ \hline
      9 & age \\ \hline
      10 & meanbp1 \\ \hline
    \end{tabular}
    \caption{Numbering used to identify the variables of the model}
    \label{tbl:ans-c-nodes}
  \end{center}
\end{table}

<<answer-c,cache=TRUE,echo=FALSE>>=
rhc.graphmod.c <- answer.c()
@

% TODO maybe better table?
<<table-c,results='asis',cache=FALSE,echo=FALSE>>=
tbl <- xtable(clique.table(rhc.graphmod.c), 
              caption = "The cliques of the resulting model for question (c)",
              align = "cc",
              label = "tbl:ans-c-cliq")
print(tbl)
@

\begin{figure}
<<graph-c,fig.keep='high',cache=FALSE,echo=FALSE>>=
g.c <- from.cliques(rhc.graphmod.c$cliques)
plot.igraph(g.c, layout = layout.circle(g.c))
@
\caption{The independence graph for question (c)}
\label{grp:ans-c-graph}
\end{figure}


%D
\item 
The Pairwaise Markov property states that any two non-adjacent variables are conditionally
independent given all the others.
Since variable node 4 (variable \emph{gender}) and node 7 (variable \emph{income}) 
are not adjacent (the edge $(4,7)$ is not present in the graph), we can conclude that:
\[ X_4 \ci X_7 | (X_1, X_2, X_3, X_5, X_6, X_7, X_8, X_9, X_{10})\] 

Using the Global Markov property we can derive a stronger statement.
Node 4 is separated from node 7 by node 6, because any path from 4 to 7 passes
through node 6, therefore \emph{gender} is independent from \emph{income} given
\emph{ninsclas} (6).

\[ X_4 \ci X_7 | X_6 \]

By the Local Markov property a variable, given its closed neighbourhood, its independent
from all remaining vertices. Therefore, in order to estimate the 
variable \emph{death} (2) (which determines whether someone survives), it is sufficient to
consider its adjacents variables: \emph{ca} (8), \emph{age} (9), \emph{meanbp1} (10).

%E
\item 
The model found starting from the saturated model (complete graph) is slightly worse 
than the model found starting from the independence model (empty graph).
% TODO I actually expected a bigger difference, check!
The BIC score of the model is 15851, whereas the BIC score of the model found in (c) is
15842. 
The model found in (e) contains more cliques than the model found (c), 
namely: $\{2, 7\}, \{3, 4\}, \{3, 9\}, \{5, 7\}, \{5, 9\}$.
However model (c) contains the following cliques, which are not included in (e):
$\{1,9\},\{3,6\},\{5,6\}$

Because of the additional nodes departing from 4 and 7 we can derive weaker independence statements
about \emph{income} and \emph{gender}, namely:
\[ X_4 \ci X_7 | (X_6, X_3) \]
\[ X_4 \ci X_7 | (X_2, X_5, X_6)\]

Also for predicting variable $X_2$ \emph{death} we need to consider a larger set of variables,
because its neighborhood includes also \emph{income} (7), in addition to \emph{ca} (8), 
\emph{age} (9), \emph{meanbp1} (10) as before.

We would like to point out that during the analysis, the IPF algorithm used in the hill-climbing
search, often failed to converge, producing therefore models of lower quality.

<<answer-e,cache=TRUE,echo=FALSE>>=
rhc.graphmod.e <- answer.e()
@

% TODO maybe better table?
<<table-e,results='asis',cache=FALSE,echo=FALSE>>=
tbl <- xtable(clique.table(rhc.graphmod.e), 
              caption = "The cliques of the resulting model for question (e)",
              align = "cc")
print(tbl)
@

\begin{figure}
<<graph-e,fig.keep='high',cache=FALSE,echo=FALSE>>=
g.e <- from.cliques(rhc.graphmod.e$cliques)
plot.igraph(g.e, layout = layout.circle(g.e))
@
\caption{The independence graph for question (e)}
\end{figure}

%F
\item
<<answer-f,cache=TRUE,echo=FALSE>>=
rhc.graphmod.f <- answer.f()
@
<<table-f-compl,results='asis',cache=FALSE,echo=FALSE>>=
tbl <- xtable(clique.table(rhc.graphmod.f$complete),
            caption = "The cliques of the resulting model for question (f), starting from the complete graph.",
            align = "cc",
            label = "tbl:ans-f-compl")
print(tbl)
@
<<table-f-empty,results='asis',cache=FALSE,echo=FALSE>>=
tbl <- xtable(clique.table(rhc.graphmod.f$empty),
            caption = "The cliques of the resulting model for question (f), starting from the empty graph.",
            align = "cc",
            label = "tbl:ans-f-empty")
print(tbl)
@
<<answer-f-scores,cache=FALSE,echo=FALSE,include=FALSE>>=
print(rhc.graphmod.f$complete$score)
@
The scores of the models starting from the complete and empty graphs are equal and are $14278$.
In addition, both models have the same cliques as can be seen in table \ref{tbl:ans-f-compl} and \ref{tbl:ans-f-empty},
and therefore also the same graph.
This indicates that the same local optima is found from both starting points.


\item
The models computed using BIC score are simpler than those found using AIC.
The former have mostly small cliques (2 verteces) whereas the latter tend to have
bigger cliques (3 verteces).
The reason lies in the difference between BIC and AIC score, namely the weight
used for the $dim(M)$ component.
This factor represents the number of non-zero u-terms and determines the complexity of the model.
For a model $M$, a small $dim(M)$ means that many u-terms are set to zero, resulting in
a independence graph will smaller cliques. For instance the independence model, in which 
all the interaction u-terms are set to 0, contains only 1-node cliques, each for every variable
of the node. Conversely, the opposite extreme is the saturated model, in which no u-terms is omitted,
that have one maximal cliques, containing all the variables of the model.
For AIC the wheight used is the constant 2, whereas for BIC it is $ln(N)$, where $N$ is the number of 
observations in the data set. The data set used in this assignment contains 
5735 rows, thus $log(5735) \approx 8.654343 > 2$.
Using the BIC score the hill-climbing algorithm converges to simpler models due to the larger penalty term,
i.e. models with fewer non-zero u-terms (smaller $dim(M)$), which result in smaller cliques.

%H
\item

<<answer-h,cache=TRUE,echo=FALSE>>=
rhc.h <- search.params()
@
<<answer-h-tbl,cache=FALSE,results='asis',echo=FALSE>>=
etab <- eval_to_df(rhc.h)
#ctab <- with(etab, tapply(error, list(nmin, minLeaf), sum))
#digits <- c(0, rep(3, dim(ctab)[2]))
tab <- xtable(etab, caption = "Result of training models with different parameters for question (h).", label = "tbl:ans-h")
print(tab)
@
We have searched for better models using the \texttt{restart} approach with different parameters.
For each parameter combination we performed 20 restarts, and both backward and forward search
was always enabled. The complete results can be seen in table \ref{tbl:ans-h}.

For the AIC scoring function, the restarting approach yields a minimally better result with a
AIC score of $14263$ for values of \texttt{prob} of $\{25\%, 50\%, 75\%\}$. The difference in AIC score
between these three values of \texttt{prob} is minimal and may well be just random noise.

For the BIC scoring function, the found models for \texttt{prob} values of
$\{25\%, 50\%\}$ have a score of $15783$. This is a minor improvement over the earlier models,
which had a best score of $15841$. 


\end{enumerate}

\begin{thebibliography}{1}

\bibitem{SPAM}
  Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt.
  \emph{SPAM E-mail Database}.
  Hewlett-Packard Labs, 1501 Page Mill Rd., 
  Palo Alto, CA 94304,
  June-July 1999.


\end{thebibliography}

\end{document}
